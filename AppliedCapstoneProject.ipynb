{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Applied Data Science Capstone - Car accident severity**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Introduction/Business Understanding**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Car collisions have been huge problems to our society and very fatal, sometimes leading to serious casulaties. Thus it is important to analyze the previously obtained data and predict before they happen. Through our capstone project, the primary goal is to build an appropriate machine learning model and predict the severity codes, which is one of the main parameters describing the severity of accidents, for collision cases.\n",
    "\n",
    "Classifying the severity of accidents using severity codes would lead to a big decrease in casualties and damages of accidents in future as people regarding this problem can use the data to improve environments such as road conditions for reducing the total property/human damages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The provided example dataset, the data of all collisions in Seattle from 2004 to present, will be used for this project. This data have 35 attributes in total including severity codes. As we do not need all the attributes, some attributes that look irrelevant to our modeling will de deleted and further data cleanings will be done."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **STEP 1: Import libraries and load the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab as pl\n",
    "import scipy.optimize as opt\n",
    "from sklearn import preprocessing,metrics\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix,jaccard_similarity_score,log_loss\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-10-30 07:19:57--  https://s3.us.cloud-object-storage.appdomain.cloud/cf-courses-data/CognitiveClass/DP0701EN/version-2/Data-Collisions.csv\n",
      "Resolving s3.us.cloud-object-storage.appdomain.cloud (s3.us.cloud-object-storage.appdomain.cloud)... 67.228.254.196\n",
      "Connecting to s3.us.cloud-object-storage.appdomain.cloud (s3.us.cloud-object-storage.appdomain.cloud)|67.228.254.196|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 73917638 (70M) [text/csv]\n",
      "Saving to: ‘Data_Collisions.csv’\n",
      "\n",
      "Data_Collisions.csv 100%[===================>]  70.49M  20.4MB/s    in 3.6s    \n",
      "\n",
      "2020-10-30 07:20:01 (19.8 MB/s) - ‘Data_Collisions.csv’ saved [73917638/73917638]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -O Data_Collisions.csv https://s3.us.cloud-object-storage.appdomain.cloud/cf-courses-data/CognitiveClass/DP0701EN/version-2/Data-Collisions.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **STEP 2: Choose which attributes to use to train machine learning model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As stated above, not all the attributes will be necessary to build effective models. Therefore I explored the csv file in advance and decided to drop some attributes such as descriptions which seem irrelevant to achieving our goal. You can check which attributes were deleted and which were chosen as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3072: DtypeWarning: Columns (33) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEVERITYCODE</th>\n",
       "      <th>ADDRTYPE</th>\n",
       "      <th>COLLISIONTYPE</th>\n",
       "      <th>PERSONCOUNT</th>\n",
       "      <th>PEDCOUNT</th>\n",
       "      <th>PEDCYLCOUNT</th>\n",
       "      <th>VEHCOUNT</th>\n",
       "      <th>INCDATE</th>\n",
       "      <th>INATTENTIONIND</th>\n",
       "      <th>UNDERINFL</th>\n",
       "      <th>WEATHER</th>\n",
       "      <th>ROADCOND</th>\n",
       "      <th>LIGHTCOND</th>\n",
       "      <th>PEDROWNOTGRNT</th>\n",
       "      <th>SPEEDING</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Intersection</td>\n",
       "      <td>Angles</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2013/03/27 00:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>Overcast</td>\n",
       "      <td>Wet</td>\n",
       "      <td>Daylight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Block</td>\n",
       "      <td>Sideswipe</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006/12/20 00:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Raining</td>\n",
       "      <td>Wet</td>\n",
       "      <td>Dark - Street Lights On</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Block</td>\n",
       "      <td>Parked Car</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2004/11/18 00:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Overcast</td>\n",
       "      <td>Dry</td>\n",
       "      <td>Daylight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Block</td>\n",
       "      <td>Other</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2013/03/29 00:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>Clear</td>\n",
       "      <td>Dry</td>\n",
       "      <td>Daylight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>Intersection</td>\n",
       "      <td>Angles</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2004/01/28 00:00:00+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Raining</td>\n",
       "      <td>Wet</td>\n",
       "      <td>Daylight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SEVERITYCODE      ADDRTYPE COLLISIONTYPE  PERSONCOUNT  PEDCOUNT  \\\n",
       "0             2  Intersection        Angles            2         0   \n",
       "1             1         Block     Sideswipe            2         0   \n",
       "2             1         Block    Parked Car            4         0   \n",
       "3             1         Block         Other            3         0   \n",
       "4             2  Intersection        Angles            2         0   \n",
       "\n",
       "   PEDCYLCOUNT  VEHCOUNT                 INCDATE INATTENTIONIND UNDERINFL  \\\n",
       "0            0         2  2013/03/27 00:00:00+00            NaN         N   \n",
       "1            0         2  2006/12/20 00:00:00+00            NaN         0   \n",
       "2            0         3  2004/11/18 00:00:00+00            NaN         0   \n",
       "3            0         3  2013/03/29 00:00:00+00            NaN         N   \n",
       "4            0         2  2004/01/28 00:00:00+00            NaN         0   \n",
       "\n",
       "    WEATHER ROADCOND                LIGHTCOND PEDROWNOTGRNT SPEEDING  \n",
       "0  Overcast      Wet                 Daylight           NaN      NaN  \n",
       "1   Raining      Wet  Dark - Street Lights On           NaN      NaN  \n",
       "2  Overcast      Dry                 Daylight           NaN      NaN  \n",
       "3     Clear      Dry                 Daylight           NaN      NaN  \n",
       "4   Raining      Wet                 Daylight           NaN      NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Data_Collisions.csv')\n",
    "df.drop(['X','Y','OBJECTID','INCKEY','COLDETKEY','REPORTNO','STATUS','INTKEY','LOCATION','SEVERITYCODE.1','SEVERITYDESC','EXCEPTRSNCODE','EXCEPTRSNDESC','INCDTTM','JUNCTIONTYPE','SDOT_COLCODE','SDOT_COLDESC','SDOTCOLNUM','ST_COLCODE','ST_COLDESC','SEGLANEKEY','CROSSWALKKEY','HITPARKEDCAR'], axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEVERITYCODE       int64\n",
      "ADDRTYPE          object\n",
      "COLLISIONTYPE     object\n",
      "PERSONCOUNT        int64\n",
      "PEDCOUNT           int64\n",
      "PEDCYLCOUNT        int64\n",
      "VEHCOUNT           int64\n",
      "INCDATE           object\n",
      "INATTENTIONIND    object\n",
      "UNDERINFL         object\n",
      "WEATHER           object\n",
      "ROADCOND          object\n",
      "LIGHTCOND         object\n",
      "PEDROWNOTGRNT     object\n",
      "SPEEDING          object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we look up on data types in our data set, many of the attirubtes are in the form of 'object', not in numerical data types such as 'int' or 'float'. We will change these data types into numerical ones in the next step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **STEP 3: Balance the data by downsampling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    136485\n",
       "2     58188\n",
       "Name: SEVERITYCODE, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['SEVERITYCODE'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CODE 1 values outnumbered CODE 2 values more than twice and we need to fix it to prevent the final result from being biased. By resample the original data, we can match the size of each value set. Downsampling is a method that creates a random subset of a bigger data set to have the same size of a smaller data set. We will apply downsampling to CODE 1 value data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2    58188\n",
      "1    58188\n",
      "Name: SEVERITYCODE, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_max = df[df['SEVERITYCODE'] == 1]\n",
    "df_min = df[df['SEVERITYCODE'] == 2]\n",
    "df_max_ds = resample(df_max,replace=False,n_samples=58188)\n",
    "\n",
    "df_balanced = pd.concat([df_max_ds,df_min])\n",
    "print(df_balanced['SEVERITYCODE'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now CODE 1 values and CODE 2 values have the same number of data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanced = df_balanced.reset_index()\n",
    "df_balanced.drop('index',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **STEP 4: Give additional cleanings for easy analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I cleaned the data by dropping unnecessary values and converting undesirable data types into numerical data types, which can be helpful for an easy analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First I checked all the attibutes and their values using value_counts() function and got rid of some rows with very low occurrences(under 50 times) as outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanced = df_balanced.drop(df_balanced[df_balanced['WEATHER'].isin([\"Blowing Sand/Dirt\", \"Severe Crosswind\", \"Partly Cloudy\"])].index)\n",
    "df_balanced = df_balanced.drop(df_balanced[df_balanced['ROADCOND'].isin([\"Sand/Mud/Dirt\", \"Oil\"])].index)\n",
    "df_balanced = df_balanced.drop(df_balanced[df_balanced['LIGHTCOND'].isin([\"Dark - Unknown Lighting\"])].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next I filled up the missing values and converted categorical values into numerical ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanced['INATTENTIONIND'] = df_balanced['INATTENTIONIND'].replace('Y',1).replace(np.nan,0)\n",
    "df_balanced['UNDERINFL'] = df_balanced['UNDERINFL'].replace('Y',1).replace('N',0).replace(np.nan,0)\n",
    "df_balanced['PEDROWNOTGRNT'] = df_balanced['PEDROWNOTGRNT'].replace('Y',1).replace(np.nan,0)\n",
    "df_balanced['SPEEDING'] = df_balanced['SPEEDING'].replace('Y',1).replace(np.nan,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanced['ADDRTYPE'] = df_balanced['ADDRTYPE'].replace(np.nan,'Unknown')\n",
    "df_balanced['COLLISIONTYPE'] = df_balanced['COLLISIONTYPE'].replace(np.nan,'Unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanced['WEATHER'] = df_balanced['WEATHER'].replace(np.nan,'Unknown')\n",
    "df_balanced['ROADCOND'] = df_balanced['ROADCOND'].replace(np.nan,'Unknown')\n",
    "df_balanced['LIGHTCOND'] = df_balanced['LIGHTCOND'].replace(np.nan,'Unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEVERITYCODE</th>\n",
       "      <th>ADDRTYPE</th>\n",
       "      <th>COLLISIONTYPE</th>\n",
       "      <th>PERSONCOUNT</th>\n",
       "      <th>PEDCOUNT</th>\n",
       "      <th>PEDCYLCOUNT</th>\n",
       "      <th>VEHCOUNT</th>\n",
       "      <th>INCDATE</th>\n",
       "      <th>INATTENTIONIND</th>\n",
       "      <th>UNDERINFL</th>\n",
       "      <th>WEATHER</th>\n",
       "      <th>ROADCOND</th>\n",
       "      <th>LIGHTCOND</th>\n",
       "      <th>PEDROWNOTGRNT</th>\n",
       "      <th>SPEEDING</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Intersection</td>\n",
       "      <td>Angles</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2019/12/25 00:00:00+00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Clear</td>\n",
       "      <td>Dry</td>\n",
       "      <td>Daylight</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Block</td>\n",
       "      <td>Parked Car</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2015/09/12 00:00:00+00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Intersection</td>\n",
       "      <td>Left Turn</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2005/03/28 00:00:00+00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Raining</td>\n",
       "      <td>Wet</td>\n",
       "      <td>Daylight</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Block</td>\n",
       "      <td>Rear Ended</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2005/09/16 00:00:00+00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Raining</td>\n",
       "      <td>Wet</td>\n",
       "      <td>Daylight</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Block</td>\n",
       "      <td>Rear Ended</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2016/10/24 00:00:00+00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Clear</td>\n",
       "      <td>Dry</td>\n",
       "      <td>Daylight</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SEVERITYCODE      ADDRTYPE COLLISIONTYPE  PERSONCOUNT  PEDCOUNT  \\\n",
       "0             1  Intersection        Angles            2         0   \n",
       "1             1         Block    Parked Car            2         0   \n",
       "2             1  Intersection     Left Turn            2         0   \n",
       "3             1         Block    Rear Ended            2         0   \n",
       "4             1         Block    Rear Ended            2         0   \n",
       "\n",
       "   PEDCYLCOUNT  VEHCOUNT                 INCDATE  INATTENTIONIND  UNDERINFL  \\\n",
       "0            0         2  2019/12/25 00:00:00+00               0          0   \n",
       "1            0         2  2015/09/12 00:00:00+00               0          0   \n",
       "2            0         2  2005/03/28 00:00:00+00               0          0   \n",
       "3            0         2  2005/09/16 00:00:00+00               0          0   \n",
       "4            0         2  2016/10/24 00:00:00+00               1          0   \n",
       "\n",
       "   WEATHER ROADCOND LIGHTCOND  PEDROWNOTGRNT  SPEEDING  \n",
       "0    Clear      Dry  Daylight              0         0  \n",
       "1  Unknown  Unknown   Unknown              0         0  \n",
       "2  Raining      Wet  Daylight              0         0  \n",
       "3  Raining      Wet  Daylight              0         0  \n",
       "4    Clear      Dry  Daylight              0         0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balanced = df_balanced.astype({'INATTENTIONIND':int,'UNDERINFL':int,'PEDROWNOTGRNT':int,'SPEEDING':int})\n",
    "df_balanced.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **STEP 5: Define the feature dataset X and the target y**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using some simple data visualizations, I decided to use the following attributes as the feature data set for my machine learning modelings: ADDRTYPE, WEATHER, ROADCOND, LIGHTCOND, PERSONCOUNT, and PEDCOUNT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Intersection', 'Clear', 'Dry', 'Daylight', 2, 0],\n",
       "       ['Block', 'Unknown', 'Unknown', 'Unknown', 2, 0],\n",
       "       ['Intersection', 'Raining', 'Wet', 'Daylight', 2, 0],\n",
       "       ['Block', 'Raining', 'Wet', 'Daylight', 2, 0],\n",
       "       ['Block', 'Clear', 'Dry', 'Daylight', 2, 0]], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df_balanced[['ADDRTYPE','WEATHER','ROADCOND','LIGHTCOND','PERSONCOUNT','PEDCOUNT']].values\n",
    "X[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviously, our target is SEVERITYCODE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df_balanced['SEVERITYCODE'].values\n",
    "y[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **STEP 6: Convert categorical values into numerical values**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the feature data set X, you can see that columns except PERSONCOUNT and PEDCOUNT consist of categorical values. I used the label encoder to get desirable data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 0, 0, 4, 2, 0],\n",
       "       [1, 7, 5, 7, 2, 0],\n",
       "       [2, 4, 6, 4, 2, 0],\n",
       "       [1, 4, 6, 4, 2, 0],\n",
       "       [1, 0, 0, 4, 2, 0]], dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le_addr = preprocessing.LabelEncoder()\n",
    "le_addr.fit(['Block','Intersection','Unknown','Alley'])\n",
    "X[:,0] = le_addr.transform(X[:,0])\n",
    "\n",
    "le_weather = preprocessing.LabelEncoder()\n",
    "le_weather.fit(['Clear','Raining','Overcast','Unknown','Snowing','Other','Fog/Smog/Smoke','Sleet/Hail/Freezing Rain'])\n",
    "X[:,1] = le_weather.transform(X[:,1])\n",
    "\n",
    "le_road = preprocessing.LabelEncoder()\n",
    "le_road.fit(['Dry','Wet','Unknown','Ice','Snow/Slush','Other','Standing Water'])\n",
    "X[:,2] = le_road.transform(X[:,2])\n",
    "\n",
    "le_light = preprocessing.LabelEncoder()\n",
    "le_light.fit(['Daylight','Dark - Street Lights On','Unknown','Dusk','Dawn','Dark - No Street Lights','Dark - Street Lights Off','Other'])\n",
    "X[:,3] = le_light.transform(X[:,3])\n",
    "\n",
    "X[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **STEP 7: Normalize the data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is necessary to normalize the data as numerical values in our feature data set shouldn't be regarded as weights on each attribute. I used data standarization to give data zero mean and unit variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1.20126503, -0.76533134, -0.7164001 ,  0.21811474, -0.37222737,\n",
       "        -0.23769606],\n",
       "       [-0.76169461,  2.27744764,  1.12174506,  2.44336761, -0.37222737,\n",
       "        -0.23769606],\n",
       "       [ 1.20126503,  0.9733995 ,  1.48937409,  0.21811474, -0.37222737,\n",
       "        -0.23769606],\n",
       "       [-0.76169461,  0.9733995 ,  1.48937409,  0.21811474, -0.37222737,\n",
       "        -0.23769606],\n",
       "       [-0.76169461, -0.76533134, -0.7164001 ,  0.21811474, -0.37222737,\n",
       "        -0.23769606]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = preprocessing.StandardScaler().fit(X).transform(X.astype(float))\n",
    "X[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **STEP 8: Split the data into train set and test set**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I set 20% of the total data set as test set and the rest as train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: (92981, 6) (92981,)\n",
      "Test set: (23246, 6) (23246,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=4)\n",
    "print ('Train set:', X_train.shape,  y_train.shape)\n",
    "print ('Test set:', X_test.shape,  y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Methodology**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I chose to use three classification algorithms - K-Nearest-Neighbors, Decesion Trees, and Logistic Regression - for machine learning modelings. Each modeling has two steps, finding the best parameter and train the model to predict."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **METHOD 1: K-Nearest-Neighbors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best accuracy was with 0.6415727436978405 with k = 17\n"
     ]
    }
   ],
   "source": [
    "Ks = 20\n",
    "mean_acc = np.zeros((Ks-1))\n",
    "std_acc = np.zeros((Ks-1))\n",
    "ConfustionMx = [];\n",
    "for n in range(1,Ks):\n",
    "    neigh = KNeighborsClassifier(n_neighbors = n).fit(X_train,y_train)\n",
    "    yhat = neigh.predict(X_test)\n",
    "    mean_acc[n-1] = metrics.accuracy_score(y_test, yhat)\n",
    "    std_acc[n-1] = np.std(yhat==y_test)/np.sqrt(yhat.shape[0])\n",
    "\n",
    "print(\"The best accuracy was with\", mean_acc.max(), \"with k =\", mean_acc.argmax()+1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=17, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_max = mean_acc.argmax()+1\n",
    "neigh = KNeighborsClassifier(n_neighbors = k_max).fit(X_train,y_train)\n",
    "neigh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 2, 1, 2])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat_knn = neigh.predict(X_test)\n",
    "yhat_knn[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Method 2: Decision Tree**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best accuracy was with 0.6524133184203734 with max depth = 7\n"
     ]
    }
   ],
   "source": [
    "Ds = 20\n",
    "mean_acc = np.zeros((Ks-1))\n",
    "std_acc = np.zeros((Ks-1))\n",
    "ConfustionMx = [];\n",
    "for n in range(1,Ks):\n",
    "    tree = DecisionTreeClassifier(criterion=\"entropy\", max_depth=n).fit(X_train,y_train)\n",
    "    pred = tree.predict(X_test)\n",
    "    mean_acc[n-1] = metrics.accuracy_score(y_test, pred)\n",
    "    std_acc[n-1] = np.std(pred==y_test)/np.sqrt(pred.shape[0])\n",
    "\n",
    "print(\"The best accuracy was with\", mean_acc.max(), \"with max depth =\", mean_acc.argmax()+1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=7,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_max = mean_acc.argmax()+1\n",
    "carTree = DecisionTreeClassifier(criterion=\"entropy\", max_depth=d_max).fit(X_train,y_train)\n",
    "carTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 2, ..., 2, 1, 1])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predTree = carTree.predict(X_test)\n",
    "predTree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Method 3: Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best accuracy was with 0.6301729329777166 with C = 0.0002\n"
     ]
    }
   ],
   "source": [
    "Cs = 20\n",
    "mean_acc = np.zeros((Ks-1))\n",
    "std_acc = np.zeros((Ks-1))\n",
    "ConfustionMx = [];\n",
    "for n in range(1,Ks):\n",
    "    LR = LogisticRegression(C=0.00005*n, solver='liblinear').fit(X_train,y_train)\n",
    "    yhat = LR.predict(X_test)\n",
    "    mean_acc[n-1] = metrics.accuracy_score(y_test, yhat)\n",
    "    std_acc[n-1] = np.std(yhat==y_test)/np.sqrt(yhat.shape[0])\n",
    "    \n",
    "print(\"The best accuracy was with\", mean_acc.max(), \"with C =\", round(0.00005*(mean_acc.argmax()+1),5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.0002, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='warn', n_jobs=None, penalty='l2', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_max = round(0.00005*(mean_acc.argmax()+1),5)\n",
    "LR = LogisticRegression(C=c_max, solver='liblinear').fit(X_train,y_train)\n",
    "LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 2, ..., 2, 1, 1])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat_lr = LR.predict(X_test)\n",
    "yhat_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_lr_prob = LR.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Results/Discussion**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will calculate the accuracy of predicting right classes for SEVERITYCODE to see each model works well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN F1 score: 0.6415727436978405\n",
      "KNN Jaccard similarity score: 0.6415727436978405\n"
     ]
    }
   ],
   "source": [
    "f1 = metrics.accuracy_score(y_test, yhat_knn)\n",
    "j1 = jaccard_similarity_score(y_test, yhat_knn)\n",
    "print(\"KNN F1 score:\", f1)\n",
    "print(\"KNN Jaccard similarity score:\", j1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree F1 score: 0.6524133184203734\n",
      "Decision Tree Jaccard similarity score: 0.6524133184203734\n"
     ]
    }
   ],
   "source": [
    "f2 = metrics.accuracy_score(y_test, predTree)\n",
    "j2 = jaccard_similarity_score(y_test, predTree)\n",
    "print(\"Decision Tree F1 score:\", f2)\n",
    "print(\"Decision Tree Jaccard similarity score:\", j2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regresiion F1 score: 0.6301729329777166\n",
      "Logistic Regression Jaccard similarity score: 0.6285382431386045\n",
      "Logistic Regression log loss: 0.6367656833415959\n"
     ]
    }
   ],
   "source": [
    "f3 = metrics.accuracy_score(y_test, yhat_lr)\n",
    "j3 = jaccard_similarity_score(y_test, yhat)\n",
    "l3 = log_loss(y_test, yhat_lr_prob)\n",
    "print(\"Logistic Regresiion F1 score:\", f3)\n",
    "print(\"Logistic Regression Jaccard similarity score:\", j3)\n",
    "print(\"Logistic Regression log loss:\", l3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KNN</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>Logistic Regression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F1 score</th>\n",
       "      <td>0.641573</td>\n",
       "      <td>0.652413</td>\n",
       "      <td>0.630173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jaccard score</th>\n",
       "      <td>0.641573</td>\n",
       "      <td>0.652413</td>\n",
       "      <td>0.628538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Log Loss</th>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>0.636766</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    KNN Decision Tree  Logistic Regression\n",
       "F1 score       0.641573      0.652413             0.630173\n",
       "Jaccard score  0.641573      0.652413             0.628538\n",
       "Log Loss             NA            NA             0.636766"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score = [f1,f2,f3]\n",
    "jaccard_score = [j1,j2,j3]\n",
    "log_loss = ['NA','NA',l3]\n",
    "res = pd.DataFrame(data=[f1_score, jaccard_score, log_loss], index=['F1 score','Jaccard score','Log Loss'], columns=['KNN','Decision Tree','Logistic Regression'])\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Conclusion**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To predict the severity codes for car collision accidents, I picked three classification algorithms - K-nearest neighbors, decision tree, and logistic regression - for machine learning modeling. From the results, we can see that all three models yielded the accuracy over 0.6 and among them the decesion tree performed best with the accuracy of 0.652413."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
